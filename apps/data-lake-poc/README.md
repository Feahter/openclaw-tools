# Data Lake POC - æµè§ˆå™¨ç«¯ SQLite + ETL æ•°æ®åŸºåº§

## ğŸ“Š é¡¹ç›®ç»Ÿè®¡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| **æ–‡ä»¶æ•°** | 20 ä¸ª |
| **ä»£ç è¡Œæ•°** | ~5500 è¡Œ |
| **é¡¹ç›®å¤§å°** | 180 KB |
| **æµ‹è¯•é€šè¿‡ç‡** | 100% (25/25) |

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. ç»Ÿä¸€æ•°æ®æ¨¡å‹
- `UnifiedData` - ç»Ÿä¸€çš„æ•°æ®è¡¨ç¤ºæ ¼å¼
- `SchemaInference` - è‡ªåŠ¨ç±»å‹æ¨æ–­
- `SchemaValidator` - Schema éªŒè¯

### 2. ETL ç®¡é“å¼•æ“
- `Pipeline` - é“¾å¼ ETL æ“ä½œ
- æ”¯æŒï¼šfilter, map, select, sort, limit, aggregate ç­‰
- æ”¯æŒè‡ªå®šä¹‰è½¬æ¢å‡½æ•°

### 3. SQL æŸ¥è¯¢å¼•æ“ (sql.js)
- å®Œæ•´ SQL æ”¯æŒï¼ˆSELECT, JOIN, GROUP BY ç­‰ï¼‰
- IndexedDB æŒä¹…åŒ–
- å¤§æ•°æ®é›†æ€§èƒ½ä¼˜åŒ–

### 4. æ€§èƒ½ä¼˜åŒ–
- `VirtualScroll` - è™šæ‹Ÿæ»šåŠ¨ï¼ˆä¸‡çº§æ•°æ®ï¼‰
- `PageLoader` - åˆ†é¡µåŠ è½½
- `Sampler` - æ•°æ®é‡‡æ ·
- `StreamProcessor` - æµå¼å¤„ç†
- `MemoryOptimizer` - å†…å­˜ä¼˜åŒ–

### 5. æ ¼å¼é€‚é…å™¨
| é€‚é…å™¨ | å¯¼å…¥ | å¯¼å‡º | è¯´æ˜ |
|--------|------|------|------|
| CSV | âœ… | âœ… | è‡ªåŠ¨åˆ†éš”ç¬¦æ£€æµ‹ |
| JSON | âœ… | âœ… | æ”¯æŒ JSONL |
| SQLite | âœ… | âœ… | sql.js é›†æˆ |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šWeb UI
```bash
cd data-lake-poc
python3 -m http.server 8080
# è®¿é—® http://localhost:8080/src/index.html
# æˆ– SQL æŸ¥è¯¢ç•Œé¢ http://localhost:8080/src/sql-query.html
```

### æ–¹å¼äºŒï¼šNode.js
```javascript
import { DataLake, Pipeline, CSVAdapter } from './src/core/schema.js';

const lake = new DataLake({ name: 'My Data Lake' });

// å¯¼å…¥æ•°æ®
const adapter = new CSVAdapter();
const data = adapter.parse(await fetch('data.csv').then(r => r.text()));
await lake.create('sales', data);

// ETL å¤„ç†
const result = await lake.createPipeline('sales')
  .filter(row => row.amount > 1000)
  .groupBy('region')
  .execute();

// SQL æŸ¥è¯¢
const sqlite = new SQLiteAdapter(lake);
await sqlite.init();
const results = sqlite.query('SELECT region, SUM(amount) FROM sales GROUP BY region');
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
data-lake-poc/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ schema.js        # ç»Ÿä¸€æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ etl.js           # ETL ç®¡é“å¼•æ“
â”‚   â”‚   â”œâ”€â”€ datalake.js      # æ•°æ®æ¹–ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ uuid.js          # UUID ç”Ÿæˆ
â”‚   â”‚   â””â”€â”€ performance.js    # æ€§èƒ½ä¼˜åŒ–
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”œâ”€â”€ csv.js           # CSV é€‚é…å™¨
â”‚   â”‚   â”œâ”€â”€ json.js          # JSON é€‚é…å™¨
â”‚   â”‚   â””â”€â”€ sqlite.js        # SQLite é€‚é…å™¨
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ indexeddb.js     # IndexedDB æŒä¹…åŒ–
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”œâ”€â”€ index.html       # ä¸» UI
â”‚   â”‚   â”œâ”€â”€ ui.js            # UI é€»è¾‘
â”‚   â”‚   â”œâ”€â”€ sql-query.html   # SQL æŸ¥è¯¢ç•Œé¢
â”‚   â”‚   â””â”€â”€ sql-ui.js        # SQL UI é€»è¾‘
â”‚   â””â”€â”€ main.js              # å…¥å£
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ run.js              # æ ¸å¿ƒæµ‹è¯•
â”‚   â””â”€â”€ sqlite.test.js       # SQLite æµ‹è¯•
â”œâ”€â”€ _meta.json               # Skill å…ƒæ•°æ®
â”œâ”€â”€ SKILL.md                 # Skill è¯´æ˜
â””â”€â”€ README.md
```

---

## ğŸ§ª æµ‹è¯•ç»“æœ

### æ ¸å¿ƒæµ‹è¯• (13/13 é€šè¿‡)
```
âœ… UnifiedData åˆ›å»º
âœ… Schema æ¨æ–­
âœ… ç±»å‹æ¨æ–­ (string/integer/float)
âœ… Pipeline (filter/map/limit/sort)
âœ… DataLake (CRUD)
âœ… CSV Parse/Write
âœ… JSON Write
```

### SQLite æµ‹è¯• (12/12 é€šè¿‡)
```
âœ… åˆå§‹åŒ–æµ‹è¯•
âœ… æŸ¥è¯¢æµ‹è¯• (SELECT/WHERE/JOIN/GROUP BY)
âœ… æ€§èƒ½æµ‹è¯• (1000è¡Œå¯¼å…¥+æŸ¥è¯¢)
âœ… DataLake é›†æˆ
âœ… å¯¼å‡ºæµ‹è¯•
```

---

## ğŸ”§ API å‚è€ƒ

### DataLake

```javascript
// åˆ›å»º
const ds = await lake.create(name, data, options);

// åˆ—è¡¨
const list = lake.list();

// åˆ é™¤
await lake.delete(id);

// ETL ç®¡é“
const pipeline = lake.createPipeline(id)
  .filter(predicate)
  .map(transform)
  .select(fields)
  .sort(field, direction)
  .limit(count);
await pipeline.execute();
```

### Pipeline

```javascript
// åˆ›å»º
const p = Pipeline.from(data, name);

// é“¾å¼æ“ä½œ
p.filter(row => row.status === 'active')
 .map(row => ({ ...row, processed: true }))
 .select(['id', 'name'])
 .sort('name', 'asc')
 .limit(100);

// æ‰§è¡Œ
const result = await p.execute();
```

### SQLite

```javascript
// åˆå§‹åŒ–
const sqlite = new SQLiteAdapter(lake);
await sqlite.init();

// ä» DataLake å¯¼å…¥
await sqlite.fromDataLake(datasetId, tableName);

// æŸ¥è¯¢
const result = sqlite.query('SELECT * FROM table LIMIT 100');

// å¯¼å‡º
const blob = await sqlite.exportBlob();
```

---

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

| æ“ä½œ | æ•°æ®é‡ | è€—æ—¶ |
|------|--------|------|
| CSV è§£æ | 10,000 è¡Œ | ~50ms |
| Pipeline å¤„ç† | 10,000 è¡Œ | ~30ms |
| SQLite å¯¼å…¥ | 1,000 è¡Œ | ~15ms |
| SQL GROUP BY | 1,000 è¡Œ | ~5ms |

---

## ğŸ”œ ä¸‹ä¸€æ­¥

- [ ] é›†æˆ Apache Arrow æ ¼å¼
- [ ] æ”¯æŒ Parquet æ–‡ä»¶
- [ ] æ·»åŠ å›¾è¡¨å¯è§†åŒ–
- [ ] å®ç°æ•°æ®é€è§†è¡¨
- [ ] æ·»åŠ åä½œåŠŸèƒ½
- [ ] æ€§èƒ½ä¼˜åŒ–ï¼ˆWeb Workerï¼‰

---

## License

MIT
