#!/usr/bin/env python3
"""
ç»Ÿä¸€å¿ƒè·³ä»»åŠ¡ - ç³»ç»Ÿè‡ªä¸»ç»´æŠ¤ä¸è¿›åŒ–
æ•´åˆï¼šèµ„æºä¼˜åŒ– + æŠ€èƒ½ç»´æŠ¤ + è¿›åŒ–åˆ†æ
é¢‘ç‡ï¼šæ¯å°æ—¶è¿è¡Œä¸€æ¬¡
"""

import json
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

# é…ç½®
WORKSPACE = Path("/Users/fuzhuo/.openclaw/workspace")
DATA_DIR = WORKSPACE / "data"
SKILLS_DIR = WORKSPACE / "skills"
TOOLS_DIR = WORKSPACE / "tools"
DATA_DIR.mkdir(parents=True, exist_ok=True)

# Skills æœç´¢ç±»åˆ«è½®æ¢
SEARCH_CATEGORIES = [
    ["web", "browser", "scraping"],
    ["database", "sql", "postgres"],
    ["file", "pdf", "docx", "xlsx"],
    ["api", "http", "request"],
    ["automation", "workflow", "cron"],
    ["testing", "jest", "playwright"],
    ["devops", "docker", "deploy"],
    ["ai", "llm", "openai"],
    ["search", "web-search"],
    ["media", "image", "audio", "video"],
]

class UnifiedHeartbeat:
    def __init__(self):
        self.timestamp = datetime.now()
        self.report = {
            "timestamp": self.timestamp.isoformat(),
            "sections": {}
        }
        
    def log(self, section: str, message: str, level: str = "info"):
        """è®°å½•æ—¥å¿—"""
        if section not in self.report["sections"]:
            self.report["sections"][section] = {"logs": [], "status": "running"}
        self.report["sections"][section]["logs"].append({
            "time": datetime.now().strftime("%H:%M:%S"),
            "level": level,
            "message": message
        })
        
    def run_command(self, cmd: str, timeout: int = 60) -> tuple:
        """è¿è¡Œ shell å‘½ä»¤"""
        try:
            result = subprocess.run(
                cmd, shell=True, capture_output=True, text=True, timeout=timeout
            )
            return result.stdout.strip(), result.stderr.strip(), result.returncode
        except subprocess.TimeoutExpired:
            return "", f"Command timed out after {timeout}s", 1
        except Exception as e:
            return "", str(e), 1

    def run_auto_archive(self):
        """æ‰§è¡Œè‡ªåŠ¨å½’æ¡£"""
        print("\n  ğŸ—‚ï¸  æ‰§è¡Œè‡ªåŠ¨å½’æ¡£...")
        try:
            archive_script = TOOLS_DIR / "auto-archive.py"
            if archive_script.exists():
                stdout, stderr, code = self.run_command(f"python {archive_script}", timeout=30)
                if code == 0:
                    self.log("resources", "è‡ªåŠ¨å½’æ¡£æ‰§è¡ŒæˆåŠŸ", "success")
                    print("    âœ… å½’æ¡£å®Œæˆ")
                else:
                    self.log("resources", f"å½’æ¡£å¤±è´¥: {stderr}", "error")
        except Exception as e:
            self.log("resources", f"å½’æ¡£å¼‚å¸¸: {e}", "error")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ¨¡å— 1: èµ„æºä¼˜åŒ–
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def run_resource_optimization(self):
        """æ‰§è¡Œèµ„æºä¼˜åŒ–æ£€æŸ¥"""
        print("\nğŸ”‹ æ¨¡å—1: èµ„æºä¼˜åŒ–")
        print("-" * 50)
        
        api_resources = {
            "minimax": {"balance": "Coding Plan (æ¯5å°æ—¶é‡ç½®)", "type": "prompt-based", "priority": "high", "status": "active"},
            "groq": {"balance": "free tier", "priority": "high", "status": "active"},
            "together_ai": {"balance": "free tier", "priority": "mid", "status": "active"},
            "deepseek": {"balance": "backup", "priority": "low", "status": "standby"},
            "siliconflow": {"balance": "backup", "priority": "low", "status": "standby"}
        }
        
        for api, info in api_resources.items():
            status_icon = "âœ…" if info["status"] == "active" else "â¸ï¸"
            print(f"  {status_icon} {api.upper()}: {info['balance']}")
            
        self.log("resources", f"æ£€æŸ¥ {len(api_resources)} ä¸ª API èµ„æºçŠ¶æ€")
        
        # æ£€æŸ¥ä»»åŠ¡çœ‹æ¿
        task_board_file = WORKSPACE / "task-board.json"
        if task_board_file.exists():
            try:
                with open(task_board_file) as f:
                    tasks = json.load(f)
                completed = sum(1 for t in tasks if t.get("status") == "done")
                total = len(tasks)
                print(f"\n  ğŸ“Š ä»»åŠ¡ç»Ÿè®¡: {completed}/{total} å·²å®Œæˆ ({completed/total*100:.0f}%)")
                self.log("resources", f"ä»»åŠ¡å®Œæˆç‡: {completed}/{total}")
            except:
                pass
        
        # 5. è‡ªåŠ¨åŒ–æœºä¼šæ‰«æ - åˆ†ææ‰§è¡Œæ—¥å¿—
        print("\n  ğŸ¤– è‡ªåŠ¨åŒ–æœºä¼šæ‰«æ")
        automation_opportunities = self.scan_automation_opportunities()
        if automation_opportunities:
            print(f"  ğŸ’¡ å‘ç° {len(automation_opportunities)} ä¸ªæ½œåœ¨è‡ªåŠ¨åŒ–æœºä¼š")
            for opp in automation_opportunities[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"    - {opp['description']} (ROI: {opp['roi']:.1f}x)")
                # å¦‚æœæ˜¯å½’æ¡£ç±»å‹ï¼Œè‡ªåŠ¨æ‰§è¡Œ
                if opp.get('action') == 'auto_archive':
                    self.run_auto_archive()
            self.log("resources", f"å‘ç° {len(automation_opportunities)} ä¸ªè‡ªåŠ¨åŒ–æœºä¼š")
        
        self.report["sections"]["resources"] = {
            "status": "success",
            "api_count": len(api_resources),
            "apis": list(api_resources.keys()),
            "automation_opportunities": len(automation_opportunities)
        }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ¨¡å— 2: Skills ç»´æŠ¤
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def run_skills_maintenance(self):
        """æ‰§è¡Œ Skills ç»´æŠ¤"""
        print("\nğŸ› ï¸  æ¨¡å—2: Skills ç»´æŠ¤")
        print("-" * 50)
        
        # 1. æ‰«ææœ¬åœ° skills
        if SKILLS_DIR.exists():
            local_skills = [d.name for d in SKILLS_DIR.iterdir() if d.is_dir() and not d.name.startswith('.')]
            print(f"  ğŸ—‚ï¸  æœ¬åœ° Skills: {len(local_skills)} ä¸ª")
            self.log("skills", f"å‘ç° {len(local_skills)} ä¸ªæœ¬åœ° skills")
        else:
            local_skills = []
            
        # 2. æ£€æŸ¥ clawdhub skills
        stdout, stderr, code = self.run_command("clawdhub list 2>/dev/null | head -20")
        clawdhub_count = len([l for l in stdout.split('\n') if l.strip() and not l.startswith(' ')])
        print(f"  ğŸ“¦ ClawdHub Skills: {clawdhub_count} ä¸ª")
        self.log("skills", f"ClawdHub å®‰è£…: {clawdhub_count} ä¸ª")
        
        # 3. æ£€æŸ¥æ›´æ–° (ç®€åŒ–ç‰ˆ)
        stdout, stderr, code = self.run_command("clawdhub update --all --dry-run 2>&1", timeout=30)
        has_updates = "update" in stdout.lower() and "already up" not in stdout.lower()
        if has_updates:
            print(f"  ğŸ”„ å‘ç°å¯æ›´æ–°")
            self.log("skills", "å‘ç°å¯æ›´æ–°çš„ skills", "alert")
        else:
            print(f"  âœ… æ‰€æœ‰ skills å·²æ˜¯æœ€æ–°")
            self.log("skills", "æ‰€æœ‰ skills å·²æ˜¯æœ€æ–°ç‰ˆæœ¬")
            
        # 4. è½®æ¢æœç´¢æ–° skills
        hour = self.timestamp.hour
        category_index = hour % len(SEARCH_CATEGORIES)
        keywords = SEARCH_CATEGORIES[category_index]
        print(f"  ğŸ” æœ¬è½®æœç´¢: {', '.join(keywords[:2])}")
        self.log("skills", f"è½®æ¢æœç´¢å…³é”®è¯: {', '.join(keywords[:2])}")
        
        # 5. æ£€æŸ¥æ˜¯å¦éœ€è¦æ·±å…¥æœç´¢ GitHubï¼ˆæ¯å¤©ä¸€æ¬¡ï¼Œåœ¨ç‰¹å®šæ—¶æ®µï¼‰
        if hour == 3:  # å‡Œæ™¨3ç‚¹è¿›è¡Œæ·±å…¥æœç´¢
            print("\n  ğŸŒ™ è¿›å…¥æ·±åº¦çŸ¥è¯†è·å–æ¨¡å¼")
            self.run_deep_knowledge_acquisition()
        
        self.report["sections"]["skills"] = {
            "status": "success",
            "local_count": len(local_skills),
            "clawdhub_count": clawdhub_count,
            "updates_available": has_updates,
            "search_keywords": keywords[:2]
        }

    def run_deep_knowledge_acquisition(self):
        """æ·±åº¦çŸ¥è¯†è·å– - æ¯å¤©ä¸€æ¬¡æœç´¢ GitHub é«˜è´¨é‡é¡¹ç›®"""
        print("    ğŸ“š æ·±åº¦çŸ¥è¯†è·å–æ¨¡å¼")
        
        # æ ¹æ®å½“å‰æŠ€èƒ½ç¼ºå£ç¡®å®šæœç´¢æ–¹å‘
        skill_gaps = self.identify_skill_gaps()
        
        for gap in skill_gaps[:2]:  # æ¯æ¬¡æœ€å¤šå¤„ç†2ä¸ªç¼ºå£
            print(f"    ğŸ” æŠ€èƒ½ç¼ºå£: {gap}")
            # è¿™é‡Œå¯ä»¥è°ƒç”¨ skill-from-github çš„æœç´¢é€»è¾‘
            # ç›®å‰åªè®°å½•å»ºè®®ï¼Œå®é™…æœç´¢éœ€è¦ GitHub API
            self.log("skills", f"å»ºè®®æœç´¢ GitHub: {gap} stars:>100", "info")
        
        if not skill_gaps:
            print("    âœ… å½“å‰æŠ€èƒ½è¦†ç›–è‰¯å¥½")
    
    def identify_skill_gaps(self) -> list:
        """è¯†åˆ«æŠ€èƒ½ç¼ºå£ - åŸºäºå½“å‰ä»»åŠ¡éœ€æ±‚
        
        ä¼˜åŒ–ç‚¹:
        - ä½¿ç”¨ set æ›¿ä»£ list è¿›è¡Œ O(1) æŸ¥é‡
        - å‡å°‘åµŒå¥—å¾ªç¯æ·±åº¦
        - æå‰è¿”å›å‡å°‘ä¸å¿…è¦çš„å¤„ç†
        """
        gaps = set()  # ä¼˜åŒ–: O(1) æŸ¥é‡
        
        # 1. æ£€æŸ¥ä»»åŠ¡çœ‹æ¿ä¸­çš„éœ€æ±‚
        task_board = WORKSPACE / "task-board.json"
        if task_board.exists():
            try:
                with open(task_board) as f:
                    tasks = json.load(f)
                
                # ä¼˜åŒ–: å•ééå†ï¼Œä½¿ç”¨ set å»é‡
                gaps.update(
                    tag for task in tasks 
                    if task.get("status") != "done"
                    for tag in task.get("tags", [])
                )
            except Exception:
                pass
        
        # 2. æ£€æŸ¥æœ€è¿‘çš„å¿ƒè·³æ—¥å¿—ä¸­çš„é”™è¯¯
        if len(gaps) < 3:  # ä¼˜åŒ–: å¦‚æœå·²æœ‰è¶³å¤Ÿç¼ºå£ï¼Œè·³è¿‡
            recent_reports = sorted(DATA_DIR.glob("heartbeat-report-*.json"))[-7:]
            for report_file in recent_reports:
                try:
                    with open(report_file) as f:
                        report = json.load(f)
                    # ä¼˜åŒ–: ä½¿ç”¨ç”Ÿæˆå™¨è¡¨è¾¾å¼
                    gaps.update(
                        f"{section}_automation"
                        for section, data in report.get("sections", {}).items()
                        if data.get("status") != "success"
                    )
                except Exception:
                    pass
                
                if len(gaps) >= 3:  # ä¼˜åŒ–: æå‰é€€å‡º
                    break
        
        # 3. è½®æ¢æ¨èï¼ˆå¦‚æœæ²¡æœ‰æ˜ç¡®çš„ç¼ºå£ï¼‰
        if not gaps:
            rotation_suggestions = [
                "data visualization", "machine learning", 
                "natural language processing", "API integration",
                "web scraping advanced", "database migration",
                "testing automation", "CI/CD pipeline"
            ]
            gaps.add(rotation_suggestions[self.timestamp.weekday() % len(rotation_suggestions)])
        
        return list(gaps)[:3]  # æœ€å¤šè¿”å›3ä¸ª
    
    def scan_automation_opportunities(self) -> list:
        """æ‰«æè‡ªåŠ¨åŒ–æœºä¼š - åŸºäºæ‰§è¡Œæ—¥å¿—åˆ†æ
        
        ä¼˜åŒ–ç‚¹:
        - ä½¿ç”¨ Counter ç®€åŒ–ç»Ÿè®¡
        - åˆå¹¶å¾ªç¯å‡å°‘éå†æ¬¡æ•°
        - é¢„åˆ†é… opportunities åˆ—è¡¨å®¹é‡
        """
        from collections import Counter
        
        opportunities = []
        
        # 1. æ£€æŸ¥å¿ƒè·³æ‰§è¡Œæ—¥å¿—
        heartbeat_logs = list(DATA_DIR.glob("heartbeat-report-*.json"))
        if len(heartbeat_logs) >= 10:
            opportunities.append({
                "type": "workflow",
                "description": f"å¿ƒè·³æŠ¥å‘Šè‡ªåŠ¨å½’æ¡£ï¼ˆå½“å‰ {len(heartbeat_logs)} ä¸ªæŠ¥å‘Šï¼‰",
                "roi": 3.0,
                "action": "auto_archive"
            })
        
        # 2. æ£€æŸ¥è¿›åŒ–æ—¥å¿—ä¸­çš„é‡å¤æ¨¡å¼
        evolution_log = DATA_DIR / "evolution-log.json"
        if evolution_log.exists():
            try:
                with open(evolution_log) as f:
                    data = json.load(f)
                    milestones = data.get("milestones", [])
                    if len(milestones) > 100:
                        opportunities.append({
                            "type": "data_management",
                            "description": f"è¿›åŒ–é‡Œç¨‹ç¢‘è‡ªåŠ¨å½’æ¡£ï¼ˆå½“å‰ {len(milestones)} æ¡è®°å½•ï¼‰",
                            "roi": 2.5,
                            "action": "auto_archive"
                        })
            except Exception:
                pass
        
        # 3. æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„æ‰‹åŠ¨ä»»åŠ¡
        task_board = WORKSPACE / "task-board.json"
        if task_board.exists():
            try:
                with open(task_board) as f:
                    tasks = json.load(f)
                
                # ä¼˜åŒ–: ä½¿ç”¨ Counter ä¸€æ¬¡æ€§ç»Ÿè®¡
                categories = Counter(
                    task.get("category", "uncategorized") 
                    for task in tasks
                )
                
                # ä¼˜åŒ–: åˆ—è¡¨æ¨å¯¼å¼æ‰¹é‡æ·»åŠ 
                opportunities.extend([
                    {
                        "type": "task_automation",
                        "description": f"'{cat}' ç±»ä»»åŠ¡æœ‰ {count} ä¸ªï¼Œå¯èƒ½å­˜åœ¨æ¨¡å¼",
                        "roi": count * 0.5,
                        "action": f"åˆ†æ '{cat}' ä»»åŠ¡ï¼Œæå–å¯è‡ªåŠ¨åŒ–æ¨¡å¼"
                    }
                    for cat, count in categories.items()
                    if count >= 5
                ])
            except Exception:
                pass
        
        return opportunities

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ¨¡å— 3: è‡ªåŠ¨çŸ¥è¯†è·å–
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def run_auto_knowledge_acquisition(self):
        """æ‰§è¡Œè‡ªåŠ¨çŸ¥è¯†è·å–ç®¡é“"""
        print("\nğŸ“š æ¨¡å—3: è‡ªåŠ¨çŸ¥è¯†è·å–")
        print("-" * 50)
        
        pipeline_script = TOOLS_DIR / "auto-knowledge-pipeline.py"
        
        if not pipeline_script.exists():
            print("  âš ï¸  è‡ªåŠ¨çŸ¥è¯†è·å–è„šæœ¬ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            self.log("knowledge", "è„šæœ¬ä¸å­˜åœ¨ï¼Œè·³è¿‡", "warning")
            self.report["sections"]["knowledge"] = {"status": "skipped", "reason": "script_not_found"}
            return
        
        print("  ğŸ¤– å¯åŠ¨è‡ªåŠ¨çŸ¥è¯†è·å–ç®¡é“...")
        
        # è¿è¡Œç®¡é“è„šæœ¬
        stdout, stderr, code = self.run_command(
            f"cd {WORKSPACE} && python {pipeline_script}", 
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        
        if code == 0:
            # è§£æè¾“å‡ºä¸­çš„å…³é”®ä¿¡æ¯
            generated_skill = None
            for line in stdout.split('\n'):
                if 'ç”ŸæˆSkill:' in line:
                    generated_skill = line.split('ç”ŸæˆSkill:')[-1].strip()
                    break
                elif 'å·²å­˜åœ¨' in line:
                    self.log("knowledge", "Skillå·²å­˜åœ¨ï¼Œè·³è¿‡", "info")
                elif 'æ‹’ç»' in line or 'è·³è¿‡' in line:
                    self.log("knowledge", "æ¡ä»¶ä¸æ»¡è¶³ï¼Œè·³è¿‡æœ¬æ¬¡", "info")
            
            if generated_skill:
                print(f"  âœ… æˆåŠŸç”Ÿæˆ Skill: {generated_skill}")
                self.log("knowledge", f"ç”Ÿæˆæ–°Skill: {generated_skill}", "success")
                self.report["sections"]["knowledge"] = {
                    "status": "success",
                    "generated_skill": generated_skill
                }
            else:
                print("  â„¹ï¸ æœ¬æ¬¡æœªç”Ÿæˆæ–°Skillï¼ˆæ¡ä»¶ä¸æ»¡è¶³æˆ–å·²å­˜åœ¨ï¼‰")
                self.report["sections"]["knowledge"] = {"status": "no_action"}
        else:
            print(f"  âŒ æ‰§è¡Œå¤±è´¥: {stderr[:200]}")
            self.log("knowledge", f"æ‰§è¡Œå¤±è´¥: {stderr[:200]}", "error")
            self.report["sections"]["knowledge"] = {"status": "error", "message": stderr[:200]}

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ¨¡å— 4: è¿›åŒ–åˆ†æ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def run_evolution_analysis(self):
        """æ‰§è¡Œè¿›åŒ–åˆ†æ"""
        print("\nğŸ§¬ æ¨¡å—4: è¿›åŒ–åˆ†æ")
        print("-" * 50)
        
        # åŠ è½½è¿›åŒ–æ•°æ®
        evolution_log_file = DATA_DIR / "evolution-log.json"
        patterns_file = DATA_DIR / "success-patterns.json"
        improvements_file = DATA_DIR / "improvements.json"
        
        patterns_count = 0
        improvements_count = 0
        
        if patterns_file.exists():
            try:
                with open(patterns_file) as f:
                    patterns = json.load(f)
                    patterns_count = len(patterns)
            except:
                pass
                
        if improvements_file.exists():
            try:
                with open(improvements_file) as f:
                    improvements = json.load(f)
                    improvements_count = len(improvements)
            except:
                pass
        
        print(f"  ğŸ“ˆ æˆåŠŸæ¨¡å¼: {patterns_count} ä¸ª")
        print(f"  ğŸ”§ å¾…æ”¹è¿›é¡¹: {improvements_count} ä¸ª")
        
        # è®°å½•æœ¬æ¬¡è¿è¡Œ
        if evolution_log_file.exists():
            try:
                with open(evolution_log_file) as f:
                    log_data = json.load(f)
            except:
                log_data = {"milestones": []}
        else:
            log_data = {"milestones": []}
            
        log_data["milestones"].append({
            "timestamp": self.timestamp.isoformat(),
            "type": "heartbeat_cycle",
            "patterns_count": patterns_count,
            "improvements_count": improvements_count
        })
        
        # åªä¿ç•™æœ€è¿‘ 50 æ¡
        log_data["milestones"] = log_data["milestones"][-50:]
        
        with open(evolution_log_file, 'w') as f:
            json.dump(log_data, f, indent=2)
        
        self.log("evolution", f"è®°å½•é‡Œç¨‹ç¢‘: æ¨¡å¼={patterns_count}, æ”¹è¿›={improvements_count}")
        
        self.report["sections"]["evolution"] = {
            "status": "success",
            "patterns_count": patterns_count,
            "improvements_count": improvements_count
        }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ä¸»è¿è¡Œå¾ªç¯
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def run(self):
        """è¿è¡Œå®Œæ•´å¿ƒè·³å‘¨æœŸ"""
        print(f"\n{'='*60}")
        print(f"ğŸ«€ ç»Ÿä¸€å¿ƒè·³ä»»åŠ¡ - {self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*60}")
        
        try:
            self.run_resource_optimization()
        except Exception as e:
            self.log("resources", f"é”™è¯¯: {str(e)}", "error")
            print(f"  âŒ èµ„æºä¼˜åŒ–å‡ºé”™: {e}")
            
        try:
            self.run_skills_maintenance()
        except Exception as e:
            self.log("skills", f"é”™è¯¯: {str(e)}", "error")
            print(f"  âŒ Skills ç»´æŠ¤å‡ºé”™: {e}")
        
        try:
            self.run_auto_knowledge_acquisition()
        except Exception as e:
            self.log("knowledge", f"é”™è¯¯: {str(e)}", "error")
            print(f"  âŒ è‡ªåŠ¨çŸ¥è¯†è·å–å‡ºé”™: {e}")
            
        try:
            self.run_evolution_analysis()
        except Exception as e:
            self.log("evolution", f"é”™è¯¯: {str(e)}", "error")
            print(f"  âŒ è¿›åŒ–åˆ†æå‡ºé”™: {e}")
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = DATA_DIR / f"heartbeat-report-{self.timestamp.strftime('%Y%m%d-%H%M')}.json"
        with open(report_file, 'w') as f:
            json.dump(self.report, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆæ‘˜è¦
        print(f"\n{'='*60}")
        print("ğŸ“‹ å¿ƒè·³æ‘˜è¦")
        print(f"{'='*60}")
        
        for section, data in self.report["sections"].items():
            icon = "âœ…" if data.get("status") == "success" else "âŒ"
            print(f"  {icon} {section.capitalize()}: {data.get('status', 'unknown')}")
        
        print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {report_file.name}")
        print(f"{'='*60}\n")
        
        return self.report

if __name__ == "__main__":
    heartbeat = UnifiedHeartbeat()
    heartbeat.run()
