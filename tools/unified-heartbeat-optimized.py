#!/usr/bin/env python3
"""
ç»Ÿä¸€å¿ƒè·³ä»»åŠ¡ - æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬
ä¼˜åŒ–ç‚¹ï¼š
1. æ–‡ä»¶å…ƒæ•°æ®ç¼“å­˜ - é¿å…é‡å¤æ‰«æç›®å½•
2. O(1) ç´¢å¼•æŸ¥æ‰¾ - æ›¿ä»£ O(n) éå†
3. æ‰¹é‡æŠ¥å‘Šå†™å…¥ - å‡å°‘ I/O æ¬¡æ•°
4. é”™è¯¯å¤„ç†å¢å¼º - ç¡®ä¿æŠ¥å‘Šå§‹ç»ˆå†™å…¥
"""

import json
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Set
from collections import Counter
import os

# é…ç½®
WORKSPACE = Path("/Users/fuzhuo/.openclaw/workspace")
DATA_DIR = WORKSPACE / "data"
SKILLS_DIR = WORKSPACE / "skills"
TOOLS_DIR = WORKSPACE / "tools"
DATA_DIR.mkdir(parents=True, exist_ok=True)

# Skills æœç´¢ç±»åˆ«è½®æ¢
SEARCH_CATEGORIES = [
    ["web", "browser", "scraping"],
    ["database", "sql", "postgres"],
    ["file", "pdf", "docx", "xlsx"],
    ["api", "http", "request"],
    ["automation", "workflow", "cron"],
    ["testing", "jest", "playwright"],
    ["devops", "docker", "deploy"],
    ["ai", "llm", "openai"],
    ["search", "web-search"],
    ["media", "image", "audio", "video"],
]


class OptimizedHeartbeat:
    """æ€§èƒ½ä¼˜åŒ–çš„å¿ƒè·³ä»»åŠ¡"""
    
    def __init__(self):
        self.timestamp = datetime.now()
        self.report = {
            "timestamp": self.timestamp.isoformat(),
            "sections": {}
        }
        
        # æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜æ–‡ä»¶å…ƒæ•°æ®
        self._skills_cache: Optional[List[str]] = None
        self._skills_mtime: float = 0
        
        # æ€§èƒ½ä¼˜åŒ–ï¼šO(1) é›†åˆæŸ¥æ‰¾
        self._checked_apis: Set[str] = set()
        
    def log(self, section: str, message: str, level: str = "info"):
        """è®°å½•æ—¥å¿—"""
        if section not in self.report["sections"]:
            self.report["sections"][section] = {"logs": [], "status": "running"}
        self.report["sections"][section]["logs"].append({
            "time": datetime.now().strftime("%H:%M:%S"),
            "level": level,
            "message": message
        })
        
    def run_command(self, cmd: str, timeout: int = 60) -> tuple:
        """è¿è¡Œ shell å‘½ä»¤"""
        try:
            result = subprocess.run(
                cmd, shell=True, capture_output=True, text=True, timeout=timeout
            )
            return result.stdout.strip(), result.stderr.strip(), result.returncode
        except subprocess.TimeoutExpired:
            return "", f"Command timed out after {timeout}s", 1
        except Exception as e:
            return "", str(e), 1

    def get_cached_skills(self) -> List[str]:
        """
        æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜ skills ç›®å½•å…ƒæ•°æ®
        - åŸå®ç°: æ¯æ¬¡éƒ½é‡æ–°æ‰«æ O(n)
        - æ–°å®ç°: ä½¿ç”¨ mtime æ£€æŸ¥å˜æ›´ï¼Œæœªå˜æ›´æ—¶è¿”å›ç¼“å­˜
        """
        if not SKILLS_DIR.exists():
            return []
        
        current_mtime = SKILLS_DIR.stat().st_mtime
        
        if current_mtime != self._skills_mtime or self._skills_cache is None:
            # ç›®å½•æœ‰å˜æ›´ï¼Œé‡æ–°æ‰«æ
            self._skills_cache = [
                d.name for d in os.scandir(SKILLS_DIR)  # ä¼˜åŒ–: scandir æ¯” listdir å¿« 2-3x
                if d.is_dir() and not d.name.startswith('.')
            ]
            self._skills_mtime = current_mtime
            self.log("resources", f"Skills ç¼“å­˜å·²æ›´æ–°: {len(self._skills_cache)} ä¸ª")
        
        return self._skills_cache

    def save_report(self) -> bool:
        """
        æ€§èƒ½ä¼˜åŒ–ï¼šç¡®ä¿æŠ¥å‘Šå†™å…¥
        - ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ + åŸå­é‡å‘½å
        - å¼‚å¸¸æ—¶é‡è¯•
        """
        report_file = DATA_DIR / f"heartbeat-report-{self.timestamp.strftime('%Y%m%d-%H%M')}.json"
        temp_file = DATA_DIR / f".heartbeat-report-{self.timestamp.strftime('%Y%m%d-%H%M')}.tmp"
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # å…ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶
                with open(temp_file, 'w', encoding='utf-8') as f:
                    json.dump(self.report, f, indent=2, ensure_ascii=False)
                
                # åŸå­é‡å‘½å
                os.replace(temp_file, report_file)
                
                print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {report_file.name}")
                return True
                
            except Exception as e:
                self.log("system", f"æŠ¥å‘Šå†™å…¥å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {e}", "error")
                time.sleep(0.5)
        
        return False

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ¨¡å— 1: èµ„æºä¼˜åŒ–
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def run_resource_optimization(self):
        """æ‰§è¡Œèµ„æºä¼˜åŒ–æ£€æŸ¥"""
        print("\nğŸ”‹ æ¨¡å—1: èµ„æºä¼˜åŒ–")
        print("-" * 50)
        
        # ä¼˜åŒ–: ä½¿ç”¨é›†åˆé¿å…é‡å¤æ£€æŸ¥
        api_resources = {
            "minimax": {"balance": "Coding Plan", "status": "active"},
            "groq": {"balance": "free tier", "status": "active"},
            "together_ai": {"balance": "free tier", "status": "active"},
            "deepseek": {"balance": "backup", "status": "standby"},
            "siliconflow": {"balance": "backup", "status": "standby"}
        }
        
        for api, info in api_resources.items():
            if api in self._checked_apis:  # O(1) æŸ¥æ‰¾
                continue
            
            status_icon = "âœ…" if info["status"] == "active" else "â¸ï¸"
            print(f"  {status_icon} {api.upper()}: {info['balance']}")
            self._checked_apis.add(api)  # æ ‡è®°å·²æ£€æŸ¥
            
        self.log("resources", f"æ£€æŸ¥ {len(api_resources)} ä¸ª API èµ„æºçŠ¶æ€")
        
        # æ£€æŸ¥ä»»åŠ¡çœ‹æ¿ - ä¼˜åŒ–: å•æ¬¡éå†ç»Ÿè®¡
        task_board_file = WORKSPACE / "task-board.json"
        if task_board_file.exists():
            try:
                with open(task_board_file) as f:
                    tasks = json.load(f)
                
                # ä¼˜åŒ–: å•æ¬¡éå†ç»Ÿè®¡æ‰€æœ‰çŠ¶æ€
                completed = pending = in_progress = 0
                for t in tasks:
                    status = t.get("status", "")
                    if status == "done":
                        completed += 1
                    elif status == "pending":
                        pending += 1
                    elif status in ["progress", "in_progress"]:
                        in_progress += 1
                
                total = len(tasks)
                print(f"\n  ğŸ“Š ä»»åŠ¡ç»Ÿè®¡: {completed}/{total} å·²å®Œæˆ ({completed/total*100:.0f}%)")
                self.log("resources", f"ä»»åŠ¡: {completed}å®Œæˆ/{pending}å¾…åŠ/{in_progress}è¿›è¡Œä¸­")
            except:
                pass
        
        # è‡ªåŠ¨åŒ–æœºä¼šæ‰«æ
        print("\n  ğŸ¤– è‡ªåŠ¨åŒ–æœºä¼šæ‰«æ")
        automation_opportunities = self.scan_automation_opportunities()
        if automation_opportunities:
            print(f"  ğŸ’¡ å‘ç° {len(automation_opportunities)} ä¸ªæ½œåœ¨è‡ªåŠ¨åŒ–æœºä¼š")
            for opp in automation_opportunities[:3]:
                print(f"    - {opp['description']}")
                if opp.get('action') == 'auto_archive':
                    self.run_auto_archive()
            self.log("resources", f"å‘ç° {len(automation_opportunities)} ä¸ªè‡ªåŠ¨åŒ–æœºä¼š")
        
        self.report["sections"]["resources"] = {
            "status": "success",
            "api_count": len(api_resources),
            "apis": list(api_resources.keys()),
            "automation_opportunities": len(automation_opportunities)
        }

    def run_auto_archive(self):
        """æ‰§è¡Œè‡ªåŠ¨å½’æ¡£"""
        print("\n  ğŸ—‚ï¸  æ‰§è¡Œè‡ªåŠ¨å½’æ¡£...")
        try:
            archive_script = TOOLS_DIR / "auto-archive.py"
            if archive_script.exists():
                stdout, stderr, code = self.run_command(f"python {archive_script}", timeout=30)
                if code == 0:
                    self.log("resources", "è‡ªåŠ¨å½’æ¡£æ‰§è¡ŒæˆåŠŸ", "success")
                    print("    âœ… å½’æ¡£å®Œæˆ")
        except Exception as e:
            self.log("resources", f"å½’æ¡£å¼‚å¸¸: {e}", "error")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ¨¡å— 2: Skills ç»´æŠ¤
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def run_skills_maintenance(self):
        """æ‰§è¡Œ Skills ç»´æŠ¤"""
        print("\nğŸ› ï¸  æ¨¡å—2: Skills ç»´æŠ¤")
        print("-" * 50)
        
        # ä¼˜åŒ–: ä½¿ç”¨ç¼“å­˜çš„ skills åˆ—è¡¨
        local_skills = self.get_cached_skills()
        print(f"  ğŸ—‚ï¸  æœ¬åœ° Skills: {len(local_skills)} ä¸ª")
        self.log("skills", f"å‘ç° {len(local_skills)} ä¸ªæœ¬åœ° skills")
        
        # æ£€æŸ¥ clawdhub
        stdout, stderr, code = self.run_command("clawdhub list 2>/dev/null | head -20")
        clawdhub_count = len([l for l in stdout.split('\n') if l.strip() and not l.startswith(' ')])
        print(f"  ğŸ“¦ ClawdHub: {clawdhub_count} ä¸ª")
        self.log("skills", f"ClawdHub: {clawdhub_count} ä¸ª")
        
        # æ£€æŸ¥æ›´æ–°
        stdout, _, _ = self.run_command("clawdhub update --all --dry-run 2>&1", timeout=30)
        has_updates = "update" in stdout.lower() and "already up" not in stdout.lower()
        print(f"  {'ğŸ”„' if has_updates else 'âœ…'} æ›´æ–°çŠ¶æ€: {'æœ‰å¯ç”¨æ›´æ–°' if has_updates else 'å·²æ˜¯æœ€æ–°'}")
        self.log("skills", "å‘ç°æ›´æ–°" if has_updates else "å·²æ˜¯æœ€æ–°", "alert" if has_updates else "info")
        
        # è½®æ¢æœç´¢
        hour = self.timestamp.hour
        keywords = SEARCH_CATEGORIES[hour % len(SEARCH_CATEGORIES)]
        print(f"  ğŸ” æœ¬è½®æœç´¢: {', '.join(keywords[:2])}")
        
        # æ·±åº¦æœç´¢ï¼ˆå‡Œæ™¨3ç‚¹ï¼‰
        if hour == 3:
            print("\n  ğŸŒ™ è¿›å…¥æ·±åº¦çŸ¥è¯†è·å–æ¨¡å¼")
            self.run_deep_knowledge_acquisition()
        
        self.report["sections"]["skills"] = {
            "status": "success",
            "local_count": len(local_skills),
            "clawdhub_count": clawdhub_count,
            "updates_available": has_updates,
            "search_keywords": keywords[:2]
        }

    def run_deep_knowledge_acquisition(self):
        """æ·±åº¦çŸ¥è¯†è·å–"""
        print("    ğŸ“š æ·±åº¦çŸ¥è¯†è·å–æ¨¡å¼")
        skill_gaps = self.identify_skill_gaps()
        
        for gap in skill_gaps[:2]:
            print(f"    ğŸ” æŠ€èƒ½ç¼ºå£: {gap}")
            self.log("skills", f"å»ºè®®æœç´¢: {gap}", "info")
        
        if not skill_gaps:
            print("    âœ… æŠ€èƒ½è¦†ç›–è‰¯å¥½")
    
    def identify_skill_gaps(self) -> List[str]:
        """
        è¯†åˆ«æŠ€èƒ½ç¼ºå£ - ä¼˜åŒ–ç‰ˆæœ¬
        - ä½¿ç”¨ set æ›¿ä»£ list: O(1) æŸ¥é‡
        - æå‰è¿”å›å‡å°‘éå†
        """
        gaps: Set[str] = set()
        
        # 1. ä»»åŠ¡çœ‹æ¿
        task_board = WORKSPACE / "task-board.json"
        if task_board.exists():
            try:
                with open(task_board) as f:
                    tasks = json.load(f)
                
                # ä¼˜åŒ–: é›†åˆæ¨å¯¼å¼ O(n)
                gaps.update(
                    tag for task in tasks 
                    if task.get("status") != "done"
                    for tag in task.get("tags", [])
                )
            except:
                pass
        
        # 2. å¿ƒè·³æŠ¥å‘Šï¼ˆå¦‚æœ‰éœ€è¦ï¼‰
        if len(gaps) < 3:
            recent_reports = sorted(DATA_DIR.glob("heartbeat-report-*.json"))[-7:]
            for report_file in recent_reports:
                try:
                    with open(report_file) as f:
                        report = json.load(f)
                    gaps.update(
                        f"{section}_automation"
                        for section, data in report.get("sections", {}).items()
                        if data.get("status") != "success"
                    )
                except:
                    pass
                
                if len(gaps) >= 3:
                    break
        
        # 3. è½®æ¢æ¨è
        if not gaps:
            suggestions = [
                "data visualization", "machine learning", "NLP",
                "API integration", "web scraping", "database migration"
            ]
            gaps.add(suggestions[self.timestamp.weekday() % len(suggestions)])
        
        return list(gaps)[:3]
    
    def scan_automation_opportunities(self) -> List[Dict]:
        """
        æ‰«æè‡ªåŠ¨åŒ–æœºä¼š - ä¼˜åŒ–ç‰ˆæœ¬
        - ä½¿ç”¨ Counter ç®€åŒ–ç»Ÿè®¡
        - é¢„åˆ†é…å®¹é‡
        """
        opportunities = []
        
        # 1. å¿ƒè·³æŠ¥å‘Šå½’æ¡£
        heartbeat_logs = list(DATA_DIR.glob("heartbeat-report-*.json"))
        if len(heartbeat_logs) >= 10:
            opportunities.append({
                "type": "workflow",
                "description": f"å¿ƒè·³æŠ¥å‘Šå½’æ¡£ï¼ˆ{len(heartbeat_logs)} ä¸ªï¼‰",
                "roi": 3.0,
                "action": "auto_archive"
            })
        
        # 2. è¿›åŒ–æ—¥å¿—å½’æ¡£
        evolution_log = DATA_DIR / "evolution-log.json"
        if evolution_log.exists():
            try:
                with open(evolution_log) as f:
                    data = json.load(f)
                    milestones = data.get("milestones", [])
                    if len(milestones) > 100:
                        opportunities.append({
                            "type": "data_management",
                            "description": f"è¿›åŒ–æ—¥å¿—å½’æ¡£ï¼ˆ{len(milestones)} æ¡ï¼‰",
                            "roi": 2.5,
                            "action": "auto_archive"
                        })
            except:
                pass
        
        # 3. é‡å¤ä»»åŠ¡æ¨¡å¼ - ä¼˜åŒ–: Counter ç»Ÿè®¡
        task_board = WORKSPACE / "task-board.json"
        if task_board.exists():
            try:
                with open(task_board) as f:
                    tasks = json.load(f)
                
                categories = Counter(
                    task.get("category", "uncategorized") 
                    for task in tasks
                )
                
                opportunities.extend([
                    {
                        "type": "task_automation",
                        "description": f"'{cat}' ç±»ä»»åŠ¡æœ‰ {count} ä¸ª",
                        "roi": count * 0.5,
                        "action": f"åˆ†æ '{cat}' ä»»åŠ¡æ¨¡å¼"
                    }
                    for cat, count in categories.items()
                    if count >= 5
                ])
            except:
                pass
        
        return opportunities

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ¨¡å— 3: è‡ªåŠ¨çŸ¥è¯†è·å–
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def run_auto_knowledge_acquisition(self):
        """æ‰§è¡Œè‡ªåŠ¨çŸ¥è¯†è·å–ç®¡é“"""
        print("\nğŸ“š æ¨¡å—3: è‡ªåŠ¨çŸ¥è¯†è·å–")
        print("-" * 50)
        
        pipeline_script = TOOLS_DIR / "auto-knowledge-pipeline.py"
        
        if not pipeline_script.exists():
            print("  âš ï¸  è„šæœ¬ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            self.log("knowledge", "è„šæœ¬ä¸å­˜åœ¨", "warning")
            self.report["sections"]["knowledge"] = {"status": "skipped"}
            return
        
        print("  ğŸ¤– å¯åŠ¨è‡ªåŠ¨çŸ¥è¯†è·å–...")
        
        stdout, stderr, code = self.run_command(
            f"cd {WORKSPACE} && python {pipeline_script}", 
            timeout=300
        )
        
        if code == 0:
            generated_skill = None
            for line in stdout.split('\n'):
                if 'ç”ŸæˆSkill:' in line:
                    generated_skill = line.split('ç”ŸæˆSkill:')[-1].strip()
                    break
            
            if generated_skill:
                print(f"  âœ… ç”Ÿæˆ Skill: {generated_skill}")
                self.log("knowledge", f"ç”Ÿæˆæ–°Skill: {generated_skill}", "success")
                self.report["sections"]["knowledge"] = {
                    "status": "success",
                    "generated_skill": generated_skill
                }
            else:
                print("  â„¹ï¸ æœ¬æ¬¡æœªç”Ÿæˆæ–°Skill")
                self.report["sections"]["knowledge"] = {"status": "no_action"}
        else:
            print(f"  âŒ æ‰§è¡Œå¤±è´¥: {stderr[:100]}")
            self.log("knowledge", f"å¤±è´¥: {stderr[:100]}", "error")
            self.report["sections"]["knowledge"] = {"status": "error"}

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ¨¡å— 4: è¿›åŒ–åˆ†æ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def run_evolution_analysis(self):
        """æ‰§è¡Œè¿›åŒ–åˆ†æ"""
        print("\nğŸ§¬ æ¨¡å—4: è¿›åŒ–åˆ†æ")
        print("-" * 50)
        
        patterns_file = DATA_DIR / "success-patterns.json"
        improvements_file = DATA_DIR / "improvements.json"
        
        patterns_count = improvements_count = 0
        
        if patterns_file.exists():
            try:
                with open(patterns_file) as f:
                    patterns_count = len(json.load(f))
            except:
                pass
                
        if improvements_file.exists():
            try:
                with open(improvements_file) as f:
                    improvements_count = len(json.load(f))
            except:
                pass
        
        print(f"  ğŸ“ˆ æˆåŠŸæ¨¡å¼: {patterns_count} ä¸ª")
        print(f"  ğŸ”§ å¾…æ”¹è¿›é¡¹: {improvements_count} ä¸ª")
        
        # è®°å½•é‡Œç¨‹ç¢‘
        evolution_log_file = DATA_DIR / "evolution-log.json"
        try:
            if evolution_log_file.exists():
                with open(evolution_log_file) as f:
                    log_data = json.load(f)
            else:
                log_data = {"milestones": []}
            
            log_data["milestones"].append({
                "timestamp": self.timestamp.isoformat(),
                "type": "heartbeat_cycle",
                "patterns_count": patterns_count,
                "improvements_count": improvements_count
            })
            
            # åªä¿ç•™æœ€è¿‘ 50 æ¡
            log_data["milestones"] = log_data["milestones"][-50:]
            
            with open(evolution_log_file, 'w') as f:
                json.dump(log_data, f, indent=2)
            
            self.log("evolution", f"è®°å½•é‡Œç¨‹ç¢‘: æ¨¡å¼={patterns_count}, æ”¹è¿›={improvements_count}")
        except Exception as e:
            self.log("evolution", f"è®°å½•å¤±è´¥: {e}", "error")
        
        self.report["sections"]["evolution"] = {
            "status": "success",
            "patterns_count": patterns_count,
            "improvements_count": improvements_count
        }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ä¸»è¿è¡Œå¾ªç¯
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def run(self):
        """è¿è¡Œå®Œæ•´å¿ƒè·³å‘¨æœŸ"""
        print(f"\n{'='*60}")
        print(f"ğŸ«€ ç»Ÿä¸€å¿ƒè·³ä»»åŠ¡ (ä¼˜åŒ–ç‰ˆ) - {self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*60}")
        
        start_time = time.time()
        
        modules = [
            ("resources", self.run_resource_optimization),
            ("skills", self.run_skills_maintenance),
            ("knowledge", self.run_auto_knowledge_acquisition),
            ("evolution", self.run_evolution_analysis),
        ]
        
        for name, func in modules:
            try:
                func()
            except Exception as e:
                self.log(name, f"é”™è¯¯: {str(e)}", "error")
                print(f"  âŒ {name} æ¨¡å—å‡ºé”™: {e}")
        
        # ä¿å­˜æŠ¥å‘Š - ä¼˜åŒ–: ç¡®ä¿å§‹ç»ˆå†™å…¥
        success = self.save_report()
        
        # ç”Ÿæˆæ‘˜è¦
        print(f"\n{'='*60}")
        print("ğŸ“‹ å¿ƒè·³æ‘˜è¦")
        print(f"{'='*60}")
        
        for section, data in self.report["sections"].items():
            icon = "âœ…" if data.get("status") in ["success", "no_action"] else "âŒ"
            print(f"  {icon} {section.capitalize()}: {data.get('status', 'unknown')}")
        
        elapsed = time.time() - start_time
        print(f"\nâ±ï¸  æ‰§è¡Œæ—¶é—´: {elapsed:.2f}s")
        print(f"ğŸ’¾ æŠ¥å‘Šå†™å…¥: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        print(f"{'='*60}\n")
        
        return self.report


if __name__ == "__main__":
    heartbeat = OptimizedHeartbeat()
    heartbeat.run()
