#!/usr/bin/env python3
"""
Skill Retriever v1.0 - è½»é‡çº§æŠ€èƒ½æ£€ç´¢å™¨
åŸºäºå…³é”®è¯åŒ¹é…å’Œæ ‡ç­¾ç³»ç»Ÿï¼Œæ— éœ€å‘é‡æ•°æ®åº“
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Tuple
from dataclasses import dataclass

@dataclass
class SkillMatch:
    name: str
    description: str
    tags: List[str]
    score: float
    reason: str
    suggested_usage: str

class SkillRetriever:
    def __init__(self, skills_dir: str = None):
        # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
        if skills_dir:
            self.skills_dir = Path(skills_dir)
        else:
            # é»˜è®¤è·¯å¾„ï¼šä»è„šæœ¬ä½ç½®å‘ä¸Šä¸¤çº§
            script_dir = Path(__file__).parent.parent.parent
            # æˆ–è€…ä½¿ç”¨ç¯å¢ƒå˜é‡
            env_path = Path('/Users/fuzhuo/.openclaw/workspace/skills')
            
            if env_path.exists():
                self.skills_dir = env_path
            elif script_dir.exists():
                self.skills_dir = script_dir
            else:
                self.skills_dir = Path('.')
        
        self.skills_index = self._build_index()
        
        # æ ‡ç­¾åŒä¹‰è¯æ˜ å°„
        self.tag_synonyms = {
            # å†™ä½œç±»
            'write': 'writing', 'writing': 'writing', 'create': 'writing',
            'text': 'writing', 'article': 'writing', 'essay': 'writing',
            'copy': 'marketing', 'copywriting': 'marketing', 'market': 'marketing',
            'sell': 'marketing', 'ad': 'marketing',
            'novel': 'fiction', 'story': 'fiction', 'fiction': 'fiction',
            
            # åˆ†æç±»
            'analyze': 'analysis', 'analysis': 'analysis', 'research': 'research',
            'logic': 'logic', 'reasoning': 'logic', 'think': 'thinking',
            'data': 'data', 'statistics': 'data', 'chart': 'data',
            
            # å¼€å‘ç±»
            'code': 'coding', 'coding': 'coding', 'program': 'coding',
            'develop': 'coding', 'script': 'scripting', 'automation': 'automation',
            'deploy': 'devops', 'docker': 'devops', 'ci': 'devops',
            'database': 'database', 'sql': 'database', 'query': 'database',
            'api': 'api', 'http': 'api', 'request': 'api',
            
            # åª’ä½“ç±»
            'image': 'image', 'photo': 'image', 'picture': 'image',
            'pdf': 'pdf', 'document': 'pdf', 'scan': 'pdf',
            'docx': 'docx', 'word': 'docx', 'ppt': 'pptx', 'excel': 'xlsx',
            'video': 'video', 'audio': 'audio',
            
            # æœç´¢ç±»
            'search': 'search', 'find': 'search', 'lookup': 'search',
            'web': 'web', 'browser': 'web', 'scrape': 'web',
            'github': 'github', 'git': 'github', 'repo': 'github',
            
            # æ€ç»´ç±»
            'brainstorm': 'brainstorm', 'idea': 'brainstorm',
            'decide': 'decision', 'decision': 'decision', 'choose': 'decision',
            'perspective': 'perspective', 'angle': 'perspective', 'view': 'perspective',
        }
    
    def _build_index(self) -> Dict:
        """æ„å»ºæŠ€èƒ½ç´¢å¼•"""
        index = {}
        skills_dir = self.skills_dir
        
        if not skills_dir.exists():
            return index
        
        for skill_dir in skills_dir.iterdir():
            if skill_dir.is_dir() and not skill_dir.name.startswith('.'):
                skill_file = skill_dir / 'SKILL.md'
                if skill_file.exists():
                    try:
                        with open(skill_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # è§£æ frontmatter
                        name, description = self._parse_frontmatter(content)
                        
                        # æå–æ ‡ç­¾ï¼ˆä»æè¿°ä¸­æ¨æ–­ï¼‰
                        tags = self._extract_tags(description, skill_dir.name)
                        
                        index[skill_dir.name] = {
                            'name': name or skill_dir.name,
                            'description': description,
                            'tags': tags,
                            'path': str(skill_dir)
                        }
                    except Exception as e:
                        print(f"Warning: Failed to parse {skill_dir.name}: {e}")
        
        return index
    
    def _parse_frontmatter(self, content: str) -> Tuple[str, str]:
        """è§£æYAML frontmatter"""
        name = ""
        description = ""
        
        if content.startswith('---'):
            parts = content.split('---', 2)
            if len(parts) >= 3:
                frontmatter = parts[1]
                # æå– name
                name_match = re.search(r'^name:\s*(.+)$', frontmatter, re.MULTILINE)
                if name_match:
                    name = name_match.group(1).strip()
                # æå– description
                desc_match = re.search(r'^description:\s*(.+)$', frontmatter, re.MULTILINE)
                if desc_match:
                    description = desc_match.group(1).strip()
        
        return name, description
    
    def _extract_tags(self, description: str, skill_name: str) -> List[str]:
        """ä»æè¿°ä¸­æå–æ ‡ç­¾"""
        tags = set()
        text = (description + ' ' + skill_name).lower()
        
        # å†™ä½œç±»
        if any(w in text for w in ['write', 'text', 'novel', 'story', 'æ–‡å­¦', 'å†™ä½œ', 'æå†™']):
            tags.add('writing')
        if any(w in text for w in ['market', 'sell', 'å®£ä¼ ', 'è¥é”€', 'æ–‡æ¡ˆ']):
            tags.add('marketing')
        if any(w in text for w in ['creative', 'åˆ›æ„', 'åˆ›ä½œ']):
            tags.add('creative')
        if any(w in text for w in ['fiction', 'novel', 'å°è¯´']):
            tags.add('fiction')
        if any(w in text for w in ['academic', 'paper', 'è®ºæ–‡', 'å­¦æœ¯']):
            tags.add('academic')
            
        # åˆ†æç±»
        if any(w in text for w in ['analyze', 'analysis', 'logic', 'é€»è¾‘', 'åˆ†æ']):
            tags.add('analysis')
        if any(w in text for w in ['logic', 'reasoning', 'æ¨ç†', 'é€»è¾‘']):
            tags.add('logic')
        if any(w in text for w in ['research', 'ç ”ç©¶', 'è°ƒç ”']):
            tags.add('research')
        if any(w in text for w in ['data', 'æ•°æ®']):
            tags.add('data')
            
        # å¼€å‘ç±»
        if any(w in text for w in ['code', 'coding', 'program', 'å¼€å‘', 'ä»£ç ']):
            tags.add('coding')
        if any(w in text for w in ['automation', 'automate', 'è‡ªåŠ¨', 'è„šæœ¬']):
            tags.add('automation')
        if any(w in text for w in ['database', 'sql', 'æ•°æ®åº“']):
            tags.add('database')
        if any(w in text for w in ['api', 'http', 'æ¥å£']):
            tags.add('api')
        if any(w in text for w in ['devops', 'deploy', 'docker', 'éƒ¨ç½²']):
            tags.add('devops')
        if any(w in text for w in ['script', 'è„šæœ¬']):
            tags.add('scripting')
            
        # åª’ä½“ç±»
        if any(w in text for w in ['image', 'picture', 'photo', 'å›¾ç‰‡', 'å›¾åƒ']):
            tags.add('image')
        if any(w in text for w in ['pdf', 'document', 'æ–‡æ¡£']):
            tags.add('pdf')
        if any(w in text for w in ['docx', 'word', 'æ–‡æ¡£']):
            tags.add('docx')
        if any(w in text for w in ['xlsx', 'excel', 'spreadsheet', 'è¡¨æ ¼']):
            tags.add('xlsx')
        if any(w in text for w in ['pptx', 'ppt', 'presentation', 'æ¼”ç¤º', 'å¹»ç¯ç‰‡']):
            tags.add('pptx')
        if any(w in text for w in ['video', 'éŸ³é¢‘', 'è§†é¢‘']):
            tags.add('media')
            
        # æœç´¢ç±»
        if any(w in text for w in ['search', 'find', 'æœç´¢', 'æŸ¥æ‰¾']):
            tags.add('search')
        if any(w in text for w in ['web', 'browser', 'scrape', 'ç½‘é¡µ', 'æµè§ˆå™¨']):
            tags.add('web')
        if any(w in text for w in ['github', 'git', 'ä»“åº“']):
            tags.add('github')
            
        # æ€ç»´ç±»
        if any(w in text for w in ['brainstorm', 'idea', 'å¤´è„‘é£æš´', 'åˆ›æ„']):
            tags.add('brainstorm')
        if any(w in text for w in ['decision', 'choose', 'å†³ç­–', 'é€‰æ‹©']):
            tags.add('decision')
        if any(w in text for w in ['thinking', 'think', 'æ€ç»´', 'æ€è€ƒ']):
            tags.add('thinking')
        if any(w in text for w in ['perspective', 'angle', 'view', 'è§†è§’']):
            tags.add('perspective')
            
        return list(tags)
    
    def _extract_query_keywords(self, query: str) -> List[str]:
        """æå–æŸ¥è¯¢å…³é”®è¯ - æ”¯æŒä¸­è‹±æ–‡"""
        query_lower = query.lower()
        
        # ä¸­æ–‡åˆ†è¯ï¼šä½¿ç”¨jiebaæˆ–ç®€å•è§„åˆ™
        # ç®€å•è§„åˆ™ï¼šæå–è¿ç»­çš„ä¸­æ–‡å­—ç¬¦å’Œè‹±æ–‡å•è¯
        import re
        
        # æå–è‹±æ–‡å•è¯
        english_words = re.findall(r'[a-zA-Z]+', query_lower)
        
        # æå–ä¸­æ–‡è¯ï¼ˆç®€å•ç­–ç•¥ï¼šå»é™¤å¸¸è§åœç”¨è¯åä¿ç•™ï¼‰
        chinese_stopwords = {'æˆ‘', 'æƒ³', 'è¦', 'çš„', 'äº†', 'åœ¨', 'æœ‰', 'æ˜¯', 'å’Œ', 'æˆ–', 'ç”¨', 'å¸®', 'æŠŠ', 
                           'è¯·', 'èƒ½', 'å¤„ç†', 'ä¸€ä¸‹', 'è¿™ä¸ª', 'é‚£ä¸ª', 'å¸®æˆ‘', 'æ‰¾', 'ä¸ª', 'æ¥', 'å»',
                           'ä¸€ä¸‹', 'çœ‹çœ‹', 'æœ‰æ²¡æœ‰', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'å¦‚ä½•', 'å¯ä»¥', 'éœ€è¦'}
        
        # ç§»é™¤åœç”¨è¯å’ŒçŸ­è¯
        keywords = []
        
        # å¤„ç†è‹±æ–‡è¯
        for word in english_words:
            if len(word) > 1 and word not in {'am', 'is', 'are', 'the', 'a', 'an', 'in', 'on', 'at', 'to', 'for', 'of', 'and', 'or'}:
                keywords.append(word)
        
        # å¤„ç†ä¸­æ–‡ï¼šç›´æ¥åŒ¹é…å…³é”®æŠ€èƒ½è¯
        skill_keywords = {
            'pdf': 'pdf', 'æ–‡æ¡£': 'pdf', 'æ–‡ä»¶': 'pdf',
            'word': 'docx', 'docx': 'docx',
            'excel': 'xlsx', 'è¡¨æ ¼': 'xlsx', 'xlsx': 'xlsx',
            'ppt': 'pptx', 'å¹»ç¯ç‰‡': 'pptx', 'æ¼”ç¤º': 'pptx',
            'å›¾ç‰‡': 'image', 'å›¾åƒ': 'image', 'photo': 'image', 'image': 'image',
            'å†™ä½œ': 'writing', 'å†™': 'writing', 'æ–‡å­—': 'writing', 'æ–‡ç« ': 'writing',
            'åˆ†æ': 'analysis', 'è§£æ': 'analysis',
            'æœç´¢': 'search', 'æŸ¥æ‰¾': 'search', 'æŸ¥': 'search',
            'ä»£ç ': 'coding', 'ç¼–ç¨‹': 'coding', 'ç¨‹åº': 'coding',
            'è‡ªåŠ¨åŒ–': 'automation', 'è‡ªåŠ¨': 'automation', 'è„šæœ¬': 'scripting',
            'æ•°æ®åº“': 'database', 'æ•°æ®': 'data', 'sql': 'database',
            'é€»è¾‘': 'logic', 'æ¨ç†': 'logic',
            'è§†è§’': 'perspective', 'è§’åº¦': 'perspective',
            'ç»†èŠ‚': 'descriptive', 'æå†™': 'descriptive', 'ç”»é¢': 'descriptive',
            'å°è¯´': 'fiction', 'æ•…äº‹': 'fiction',
            'å­¦æœ¯': 'academic', 'è®ºæ–‡': 'academic',
            'è¥é”€': 'marketing', 'æ–‡æ¡ˆ': 'marketing', 'å®£ä¼ ': 'marketing',
            'é—®é¢˜': 'thinking', 'æ€è€ƒ': 'thinking', 'æ€ç»´': 'thinking',
            'æ¸…å•': 'checklist', 'åˆ—è¡¨': 'checklist',
            'github': 'github', 'git': 'github',
            'æµè§ˆå™¨': 'web', 'ç½‘é¡µ': 'web', 'çˆ¬å–': 'web',
            'è§†é¢‘': 'media', 'éŸ³é¢‘': 'media',
        }
        
        for cn, tag in skill_keywords.items():
            if cn in query_lower:
                keywords.append(tag)
                keywords.append(cn)  # åŒæ—¶ä¿ç•™åŸå§‹ä¸­æ–‡è¯
        
        # å»é‡
        keywords = list(set(keywords))
        
        return keywords
    
    def _calculate_match_score(self, query: str, keywords: List[str], skill: Dict) -> Tuple[float, str]:
        """è®¡ç®—åŒ¹é…åˆ†æ•°"""
        name = skill['name'].lower()
        description = skill['description'].lower()
        tags = skill['tags']
        
        # åç§°åŒ¹é… (40%)
        name_score = 0
        if any(kw in name for kw in keywords):
            name_score = sum(1 for kw in keywords if kw in name) / len(keywords)
            name_score = min(name_score * 1.5, 1.0)  # åç§°åŒ¹é…æƒé‡é«˜
        
        # æè¿°åŒ¹é… (30%)
        desc_score = 0
        if any(kw in description for kw in keywords):
            desc_score = sum(1 for kw in keywords if kw in description) / len(keywords)
        
        # æ ‡ç­¾åŒ¹é… (30%)
        tag_score = 0
        query_tags = set()
        for kw in keywords:
            if kw in self.tag_synonyms:
                query_tags.add(self.tag_synonyms[kw])
        
        if query_tags and tags:
            matched_tags = set(tags) & query_tags
            tag_score = len(matched_tags) / max(len(query_tags), 1)
        
        # æ€»åˆ†
        total_score = name_score * 0.4 + desc_score * 0.3 + tag_score * 0.3
        
        # ç”ŸæˆåŸå› 
        reasons = []
        if name_score > 0.5:
            reasons.append("åç§°åŒ¹é…")
        if desc_score > 0.3:
            reasons.append("æè¿°ç›¸å…³")
        if tag_score > 0.3:
            reasons.append("æ ‡ç­¾åŒ¹é…")
        
        reason = "ã€".join(reasons) if reasons else "å¼±ç›¸å…³"
        
        return total_score, reason
    
    def _generate_suggested_usage(self, skill_name: str, query: str) -> str:
        """ç”Ÿæˆå»ºè®®ç”¨æ³•"""
        # ä»æŸ¥è¯¢ä¸­æå–åŠ¨ä½œå’Œå¯¹è±¡
        patterns = [
            r'(?:ç”¨|ä½¿ç”¨)\s*(.+?)(?:æ¥|å»)?(.+)',
            r'(?:æ€ä¹ˆ|å¦‚ä½•)(.+?)',
            r'(.+?)(?:ç›¸å…³çš„|æœ‰å…³çš„)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, query)
            if match:
                action = match.group(1).strip()
                return f"ç”¨{skill_name}æ¥{action}"
        
        return f"ä½¿ç”¨ {skill_name} æŠ€èƒ½"
    
    def search(self, query: str, top_k: int = 5) -> List[SkillMatch]:
        """æœç´¢æŠ€èƒ½"""
        keywords = self._extract_query_keywords(query)
        
        if not keywords:
            return []
        
        matches = []
        for skill_id, skill in self.skills_index.items():
            score, reason = self._calculate_match_score(query, keywords, skill)
            
            if score > 0.1:  # é˜ˆå€¼è¿‡æ»¤
                matches.append(SkillMatch(
                    name=skill['name'],
                    description=skill['description'],
                    tags=skill['tags'],
                    score=score,
                    reason=reason,
                    suggested_usage=self._generate_suggested_usage(skill['name'], query)
                ))
        
        # æ’åº
        matches.sort(key=lambda x: x.score, reverse=True)
        
        return matches[:top_k]
    
    def search_by_tag(self, tag: str) -> List[SkillMatch]:
        """æŒ‰æ ‡ç­¾æœç´¢"""
        # æ ‡å‡†åŒ–æ ‡ç­¾
        normalized_tag = self.tag_synonyms.get(tag.lower(), tag.lower())
        
        matches = []
        for skill_id, skill in self.skills_index.items():
            if normalized_tag in skill['tags']:
                matches.append(SkillMatch(
                    name=skill['name'],
                    description=skill['description'],
                    tags=skill['tags'],
                    score=0.9,
                    reason=f"æ ‡ç­¾åŒ¹é…: {normalized_tag}",
                    suggested_usage=f"ä½¿ç”¨ {skill['name']} æŠ€èƒ½"
                ))
        
        return matches
    
    def list_all_skills(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰æŠ€èƒ½"""
        return [
            {
                'name': s['name'],
                'description': s['description'][:100] + '...' if len(s['description']) > 100 else s['description'],
                'tags': s['tags']
            }
            for s in self.skills_index.values()
        ]


def main():
    """CLIå…¥å£"""
    import sys
    
    retriever = SkillRetriever()
    
    if len(sys.argv) < 2:
        print("Usage: python skill_retriever.py <query>")
        print("       python skill_retriever.py --list")
        print("       python skill_retriever.py --tag <tag>")
        sys.exit(1)
    
    if sys.argv[1] == '--list':
        skills = retriever.list_all_skills()
        print(f"\nå…± {len(skills)} ä¸ªæŠ€èƒ½ï¼š\n")
        for skill in sorted(skills, key=lambda x: x['name']):
            tags_str = ', '.join(skill['tags']) if skill['tags'] else 'æ— æ ‡ç­¾'
            print(f"ğŸ“¦ {skill['name']}")
            print(f"   {skill['description']}")
            print(f"   æ ‡ç­¾: {tags_str}\n")
    
    elif sys.argv[1] == '--tag' and len(sys.argv) > 2:
        tag = sys.argv[2]
        matches = retriever.search_by_tag(tag)
        print(f"\næ ‡ç­¾ '{tag}' ç›¸å…³æŠ€èƒ½ ({len(matches)} ä¸ª)ï¼š\n")
        for match in matches:
            print(f"ğŸ“¦ {match.name}")
            print(f"   {match.description[:80]}...")
            print(f"   æ ‡ç­¾: {', '.join(match.tags)}\n")
    
    else:
        query = ' '.join(sys.argv[1:])
        matches = retriever.search(query)
        
        if not matches:
            print(f"\næœªæ‰¾åˆ°ä¸ '{query}' ç›¸å…³çš„æŠ€èƒ½")
            print("\nè¯•è¯•è¿™äº›å…³é”®è¯ï¼š")
            print("  - å†™ä½œç±»: write, creative, text, novel")
            print("  - åˆ†æç±»: analyze, logic, data, research")
            print("  - å¼€å‘ç±»: code, api, database, automation")
            print("  - æœç´¢ç±»: search, web, github")
            print("  - åª’ä½“ç±»: image, pdf, docx, video")
            sys.exit(0)
        
        print(f"\næ‰¾åˆ° {len(matches)} ä¸ªç›¸å…³æŠ€èƒ½ï¼š\n")
        
        for i, match in enumerate(matches, 1):
            score_pct = int(match.score * 100)
            icon = "ğŸ”¥" if score_pct >= 80 else "ğŸ“" if score_pct >= 60 else "âœ¨"
            
            print(f"{i}. {icon} {match.name} (åŒ¹é…åº¦: {score_pct}%)")
            print(f"   {match.description}")
            print(f"   æ ‡ç­¾: {', '.join(match.tags) if match.tags else 'æ— '}")
            print(f"   åŸå› : {match.reason}")
            print(f"   å»ºè®®: \"{match.suggested_usage}\"\n")


if __name__ == '__main__':
    main()
